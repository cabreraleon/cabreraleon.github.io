---
layout: post
title: Module 3 - Experiment 2
---

My Module 3 Experiment 2 is on Varying the Sampling Techniques for PRMs. I will be experimenting with Uniform Random Free, Gaussian, Obstacle-Based Probabilistic Roadmap (OBPRM), Medial Axis Probabilistic Roadmap (MAPRM), and Bridge Test algorithms for sampling. 

<br>

## Running A Motion Planning Experiment
  First, I created a copy of the CfgExamples.xml file used in Module 3 Part 1 and renamed it MyCfgExamples.xml. This allows me to experiment with the code freely without changing the original file that contains the shared source code. SInce I am no longer using the maze benchmark, I will have to change my code to specify that the 3D environment and the 3D boxy robot will be used and change the labels accordingly. 

        <Problem baseFilename="3d">
          <Environment filename="3D/3d.env"
            frictionCoefficient="0" gravity="0 0 0"/>
          <Robot label="boxy" filename="3D/boxy.robot">
            <Agent type="planning"/>
            <Agent type="pathfollowing" 
              waypointDm="euclideanPosition"
              waypointThreshold=".05"/>
          </Robot>
          <Task label="query" robot="boxy">
            <StartConstraints>

  Since boxy.robot has more DOF than the maze.robot, I also have to make changes to the start and goal constraint nodes. 

        <StartConstraints>
        <!-- WARNING Support for multiple constraints is   
          not yet implemented! -->
        <CSpaceConstraint point="0 0 0 0 0 0"/>
      </StartConstraints>
      <GoalConstraints>
        <!-- Here multiple constraints indicates a compound    
          goal. Each constraint represents a single  
          intermediate goal. -->
        <CSpaceConstraint point="20 5 10 0.2 0.8 0.5"/>
      </GoalConstraints>
    </Task>
  <br>

  ---

  <br>

## Experimental Setup
  Before starting my experiments,  I searched for the <ConditionalEvaluator> node for the NodesEval label and changed the value from 1000 to 1. This ensures that at least 1 node exists before terminating for each sampling experiment.

        <ConditionalEvaluator label="NodesEval" metric_method="NumNodes" value="1" operator=">="/>

  ### Uniform Random Free Sampler 

  1. In the < MPStrategies > section, I set the < Sampler > label as “UniformRandomFree”.

  2. I commented out all the Connector nodes. The connectors have been commented out because for now, we will only be evaluating the samples, which are represented by nodes, so we do not need the connectors, which are represented by edges. I also ensured that the <Evaluator> node is set to “NodesEval.” 
  3. I returned to the PRM-build section and changed the UniformRandomFree number from 1 to 100. This states that when sampling, 100 samples are generated with 1 attempt per sample. In other words, we can generate anywhere from 1 to 100 samples. 

  The code for this experiment should look like this after Steps 1-4. <br>
  `      `  <MPStrategies>
            <!-- Basic PRM where num samples is based on Number -->
              <BasicPRM label="BasicPRM1" debug="true" querySampler="UniformRandomFree">
                <Sampler label="UniformRandomFree" number="100" attempts="1"/>
                <!--Connector label="Closest"/-->
                <!--Connector label="ConnectCCs"/-->
                <Evaluator label="NodesEval"/>
              </BasicPRM>`
  `
  <br>

  Note that the Sampler label for the BasicPRM node is “UniformRandomFree”, so any experiment run with this xml code will be for uniform sampling. I ran PMPL by writing the commands “make pmpl” and “ ../pmpl -f MyCfgExamples.xml” to generate a .map and .stat file. In doing so, I completed uniform sampling. Therefore, I renamed those files to Uniform.map and Uniform.stat.

  ### Obstacle-Based PRM (OBPRM) Sampler
  4. The same steps were followed for this sampler, except under the <MPStategies> section, the Sampler node’s label was set to OBPRM. Then, I ran pmpl and completed OBPRM sampling. I renamed the output files to OBPRM.map, OBPRM.stat, and OBPRM.vd.

  <MPStrategies>
    <!-- Basic PRM where num samples is based on Number -->
      <BasicPRM label="BasicPRM1" debug="true" querySampler="UniformRandomFree">
        <Sampler label="OBPRM" number="100" attempts="1"/>
        <!--Connector label="Closest"/-->
        <!--Connector label="ConnectCCs"/-->
        <Evaluator label="NodesEval"/>
      </BasicPRM>


  ### Medial-Axis PRM (MAPRM)
  5. The same steps were followed for this sampler, except under the <MPStategies> section, the Sampler node’s label was set to “MAPRM”. Then, I ran pmpl and completed OBPRM sampling. I renamed the output files to MAPRM.map and MAPRM.stat.
  <MPStrategies>
    <!-- Basic PRM where num samples is based on Number-->
      <BasicPRM label="PRM-build" debug="true"   querySampler="UniformRandomFree">
        <Sampler label="MAPRM" number="100" attempts="1"/>
        <!--Connector label="Closest"/-->
        <!--Connector label="ConnectCCs"/-->
        <Evaluator label="NodesEval"/>
      </BasicPRM>

  ### Gaussian Sampler
  6. The same steps were followed for this sampler, except under the <MPStategies> section, the Sampler node’s label was set to “Gauss”. Then, I ran pmpl and completed OBPRM sampling. I renamed the output files to Gauss.map, Gauss.stat, and Gauss.vd.
  
  <MPStrategies>
    <!-- Basic PRM where num samples is based on Number -->
      <BasicPRM label="PRM-build" debug="true" querySampler="UniformRandomFree">
        <!--Connector label="Closest"/-->
        <!--Connector label="ConnectCCs"/-->
        <Sampler label="Gauss" number="100" attempts="1"/>
        <Evaluator label="NodesEval"/>
      </BasicPRM>

  ### Bridge Sampler
  7. The same steps were followed for this sampler, except under the MPStategies label, the Sampler node’s label was set to “Bridge”. Then, I ran pmpl and completed OBPRM sampling. I renamed the output files to Bridge.map, Bridge.stat, Bridge.vd.

  <MPStrategies>
    <!-- Basic PRM where num samples is based on Number -->
      <BasicPRM label="PRM-build" debug="true" querySampler="UniformRandomFree">
        <Sampler label="Bridge" number="100" attempts="1"/>
        <!--Connector label="Closest"/-->
        <!--Connector label="ConnectCCs"/-->
        <Evaluator label="NodesEval"/>
      </BasicPRM>
<br>

---

<br>

## Collecting Data with GNU
  After I ran PMPL for each sampler, I used the .stat output files to collect my experimental data.  In a nodes.dat file, I recorded the number of successful nodes added to the roadmap. In a cd.dat file, I recorded collision detector calls made when the roadmap ran. I used a script to graph the two .dat files with gnuplot.

  ![fig34](https://cabreraleon.github.io/images/fig34.png) <br>
  **Figure 34. Nodes Generated by Distinct Sampling-based Planners** <br>
  <br>


  ![fig35](https://cabreraleon.github.io/images/fig35.png) <br>
  **Figure 35. Collision Detection calls Required by Distinct Sampling-based Planners** <br>
  <br>

## My Modifications
  I did not know what the “attempts” label in the Sample node, so my curiosity led me to see what would happen if I changed the attempts value.

      <Sampler label="UniformRandomFree" number=”n" attempts="1"/>

      <Sampler label="OBPRM" number="100" attempts="1"/>
    
  *Incremental Attempts for Uniform Sampler:* The attempts made by a Uniform sampler does not significantly affect the success rate of the nodes added to the roadmap. There is no difference between a sampler running 100 samples at 10 attempts versus running 100 samples at 100 attempts. The ratio of number of nodes per CD call is close to 1:1, which is quite uniform. <br>

 ![fig36](https://cabreraleon.github.io/images/fig36.png) <br>
  **Figure 36. Nodes and CD calls Generated by Uniform with Varying Attempt Values** <br>
  <br>

  *Incremental Attempts for OBPRM Sample:* The number of attempts significantly increases the collisions detected for the OBPRM sample. The number of successful nodes generated also increases but not as significantly. The largest increase was going from 1 attempt, which generated 233,287 CD calls, to 10 attempts, which generated 1,056,911 CD calls. <br>


  ![fig37](https://cabreraleon.github.io/images/fig37.png) <br>
  **Figure 37. Nodes and CD calls Generated by OBPRM with Varying Attempt Values** <br>
  <br>

  I discovered that **attempts** affect motion planner results. When you want to insist on getting n number of samples each time you call the sampler but you only want to insist x amount of times, you must set the number of attempts to the value of x.

<br>

---

<br>

## Visualizing Data with Vizmo
  I used the .map files to visualize my results on Vizmo. The image below shows samples collected by four samplers. Each cube below is a sample, the thin horizontal rectangles are obstacles, and all C-space elements are in the 3D environment. My main observation is OBPRM is more efficient in sampling in an environment with a narrow passage. <br>
  <br>

  ### Uniform Random Roadmap
   Has more nodes (samples), nodes are located all over the space, nodes seem random. There seems to be a struggle with the nodes near the narrow passage between the obstacles. The success rate is proportional to free space volume. <br>

   ![fig38](https://cabreraleon.github.io/images/fig38.png) <br>
   **Figure 38. Uniform Random Roadmap Results** <br>
    <br>

  ### OBPRM Roadmap
   Has significantly less nodes (samples), nodes don’t seem randomly placed. Instead, nodes seem like they have been strategically placed in the environment efficiently and the narrow passage between the obstacles seems to be smoother. OBPRM pushes samples, so it is unlikely to fail. <br>
   ![fig39](https://cabreraleon.github.io/images/fig39.png) <br>
   **Figure 39. OBPRM Roadmap Results** <br>
  <br>

  ### Medial-Axis PRM Roadmap
   The samples generated by the MAPRM appear to be retracted onto the medial axis of the free space but there also seems to be a few couple of samples within the narrow passage. The sampler has explored the narrow passage with less nodes than the PRM. <br>
   ![fig40](https://cabreraleon.github.io/images/fig40.png) <br>
    **Figure 40. Medial-Axis PRM Roadmap Results** <br>
  <br>

  ### Gaussian Roadmap 
   The Gaussian roadmap only has 2 samples. One is farther on the outside of the obstacles And the other sample is directly within the narrow C-Free space between the two obstacles.
   ![fig41](https://cabreraleon.github.io/images/fig41.png) <br>
   **Figure 41. Gaussian Roadmap Results** <br>
  <br>

  ### Bridge Roadmap
   The Bridge roadmap only has 2 samples. Like the Gaussian, one sample is farther on the outside of the obstacles and the other sample is directly within the narrow Cfree space between the two obstacles. It looks identical to the Gaussian roadmap. I ran this experiment twice to make sure I didn’t make an error because of how identical the Bridge results and Gaussian results looked.
   ![fig42](https://cabreraleon.github.io/images/fig42.png) <br>
   **Figure 42. Bridge Roadmap Results**
